{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#--------------Importing Files-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIT=open('C:\\Python\\MIT.txt',encoding=\"utf8\").read()\n",
    "Stanford=open('C:\\Python\\Stanford.txt',encoding=\"utf8\").read()\n",
    "Tesla=open('C:\\Python\\Tesla.txt',encoding=\"utf8\").read()\n",
    "UIC=open('C:\\\\Python\\\\UIC.txt',encoding=\"utf8\").read()\n",
    "UIS=open('C:\\\\Python\\\\UIS.txt',encoding=\"utf8\").read()\n",
    "UIUC=open('C:\\\\Python\\\\UIUC.txt',encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#----------Tokenizing Files-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIT_Tokenize=(word_tokenize(MIT))\n",
    "Stanford_Tokenize=(word_tokenize(Stanford))\n",
    "Tesla_Tokenize=(word_tokenize(Tesla))\n",
    "UIC_Tokenize=(word_tokenize(UIC))\n",
    "UIS_Tokenize=(word_tokenize(UIS))\n",
    "UIUC_Tokenize=(word_tokenize(UIUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-----Converting All data to Lower Case----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIT_Tokenize     = [w.lower() for w in  MIT_Tokenize]\n",
    "Stanford_Tokenize= [w.lower() for w in  Stanford_Tokenize]\n",
    "Tesla_Tokenize   = [w.lower() for w in  Tesla_Tokenize]\n",
    "UIC_Tokenize     = [w.lower() for w in  UIC_Tokenize]\n",
    "UIS_Tokenize     = [w.lower() for w in  UIS_Tokenize]\n",
    "UIUC_Tokenize    = [w.lower() for w in  UIUC_Tokenize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------Removing Punctuations-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punct(data):\n",
    "    l2=list()\n",
    "    #symbols=string.punctuation\n",
    "    #symbols=symbols + \"''\"\n",
    "    for i in data:\n",
    "        if(i.isalpha() or i.isnumeric()):\n",
    "            #print(i)\n",
    "            l2.append(i)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIT_TOK_WO_P=rem_punct(MIT_Tokenize)\n",
    "STA_TOK_WO_P=rem_punct(Stanford_Tokenize)\n",
    "TES_TOK_WO_P=rem_punct(Tesla_Tokenize)\n",
    "UIC_TOK_WO_P=rem_punct(UIC_Tokenize)\n",
    "UIUC_TOK_WO_P=rem_punct(UIUC_Tokenize)\n",
    "UIS_TOK_WO_P=rem_punct(UIS_Tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------Filtering Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_wrd=set(stopwords.words('english'))\n",
    "def rem_stop_words(data):\n",
    "    l3=list()\n",
    "    for i in data:\n",
    "        if(i not in stp_wrd):\n",
    "            l3.append(i)\n",
    "    return l3\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIT_WO_P_STP_WRD=rem_stop_words(MIT_TOK_WO_P)\n",
    "STA_WO_P_STP_WRD=rem_stop_words(STA_TOK_WO_P)\n",
    "TES_WO_P_STP_WRD=rem_stop_words(TES_TOK_WO_P)\n",
    "UIC_WO_P_STP_WRD=rem_stop_words(UIC_TOK_WO_P)\n",
    "UIUC_WO_P_STP_WRD=rem_stop_words(UIUC_TOK_WO_P)\n",
    "UIS_WO_P_STP_WRD=rem_stop_words(UIS_TOK_WO_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------Stemming-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemm(data):\n",
    "    l1=list()\n",
    "    for word in data:\n",
    "        l1.append(ps.stem(word))\n",
    "    return l1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIT_Stem=stemm(MIT_WO_P_STP_WRD)\n",
    "Stanford_Stem=stemm(STA_WO_P_STP_WRD)\n",
    "Tesla_Stem=stemm(TES_WO_P_STP_WRD)\n",
    "UIC_Stem=stemm(UIC_WO_P_STP_WRD)\n",
    "UIUC_Stem=stemm(UIUC_WO_P_STP_WRD)\n",
    "UIS_Stem=stemm(UIS_WO_P_STP_WRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-------------------Jaccardian Similarity-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardian_similarity(file1,file2):\n",
    "    f1=set(file1)\n",
    "    f2=set(file2)\n",
    "    inter=f1.intersection(f2)\n",
    "    return float(len(inter)/ (len(f1) + len(f2) - len(inter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIC_MIT_JAC_SIM=jaccardian_similarity(UIC_Stem,MIT_Stem)\n",
    "UIC_Stanford_JAC_SIM=jaccardian_similarity(UIC_Stem,Stanford_Stem)\n",
    "UIC_Tesla_JAC_SIM=jaccardian_similarity(UIC_Stem,Tesla_Stem)\n",
    "UIC_UIUC_JAC_SIM=jaccardian_similarity(UIC_Stem,UIUC_Stem)\n",
    "UIC_UIS_JAC_SIM=jaccardian_similarity(UIC_Stem,UIS_Stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccardian similarity between UIC and MIT      ->  0.21282722513089006\n",
      "Jaccardian similarity between UIC and Stanford ->  0.2669418644650843\n",
      "Jaccardian similarity between UIC and Tesla    ->  0.19287576020851432\n",
      "Jaccardian similarity between UIC and UIUC     ->  0.2971014492753623\n",
      "Jaccardian similarity between UIC and UIS      ->  0.23725212464589235\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccardian similarity between UIC and MIT      -> \" , UIC_MIT_JAC_SIM)\n",
    "print(\"Jaccardian similarity between UIC and Stanford -> \" , UIC_Stanford_JAC_SIM)\n",
    "print(\"Jaccardian similarity between UIC and Tesla    -> \" , UIC_Tesla_JAC_SIM)\n",
    "print(\"Jaccardian similarity between UIC and UIUC     -> \" , UIC_UIUC_JAC_SIM)\n",
    "print(\"Jaccardian similarity between UIC and UIS      -> \" , UIC_UIS_JAC_SIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-----Calculating Jaccardian Similarity using NLTK Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21282722513089003\n",
      "0.2669418644650843\n",
      "0.19287576020851438\n",
      "0.2971014492753623\n",
      "0.2372521246458924\n"
     ]
    }
   ],
   "source": [
    "# Calculating Jaccardian Distances\n",
    "# Similarity is the inverse of Distance\n",
    "\n",
    "print(1-nltk.jaccard_distance(set(MIT_Stem),set(UIC_Stem)))\n",
    "print(1-nltk.jaccard_distance(set(Stanford_Stem),set(UIC_Stem)))\n",
    "print(1-nltk.jaccard_distance(set(Tesla_Stem),set(UIC_Stem)))\n",
    "print(1-nltk.jaccard_distance(set(UIUC_Stem),set(UIC_Stem)))\n",
    "print(1-nltk.jaccard_distance(set(UIS_Stem),set(UIC_Stem)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-------------- Cosine Similarity---------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostring(data):\n",
    "    txt=\"\"\n",
    "    for i in data:\n",
    "        txt=txt + \" \"+i\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_sim (file1,file2):\n",
    "    t1=tostring(file1)\n",
    "    t2=tostring(file2)\n",
    "    text=[t1,t2]\n",
    "    vct=TfidfVectorizer(text)\n",
    "    tfidf=vct.fit_transform(text)\n",
    "    return(tfidf*tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIC_MIT_COSINE_SIM=pairwise_sim(MIT_Stem,UIC_Stem).toarray()[0,1]\n",
    "UIC_Stanford_COSINE_SIM=pairwise_sim(Stanford_Stem,UIC_Stem).toarray()[0,1]\n",
    "UIC_Tesla_COSINE_SIM=pairwise_sim(Tesla_Stem,UIC_Stem).toarray()[0,1]\n",
    "UIC_UIUC_COSINE_SIM=pairwise_sim(UIUC_Stem,UIC_Stem).toarray()[0,1]\n",
    "UIC_UIS_COSINE_SIM=pairwise_sim(UIS_Stem,UIC_Stem).toarray()[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between UIC and MIT      ->  0.2718840396311301\n",
      "Cosine similarity between UIC and Stanford ->  0.36344152923779754\n",
      "Cosine similarity between UIC and Tesla    ->  0.14323842813077178\n",
      "Cosine similarity between UIC and UIUC     ->  0.7606539532776375\n",
      "Cosine similarity between UIC and UIS      ->  0.49867639277004416\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between UIC and MIT      -> \" , UIC_MIT_COSINE_SIM)\n",
    "print(\"Cosine similarity between UIC and Stanford -> \" , UIC_Stanford_COSINE_SIM)\n",
    "print(\"Cosine similarity between UIC and Tesla    -> \" , UIC_Tesla_COSINE_SIM)\n",
    "print(\"Cosine similarity between UIC and UIUC     -> \" , UIC_UIUC_COSINE_SIM)\n",
    "print(\"Cosine similarity between UIC and UIS      -> \" , UIC_UIS_COSINE_SIM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
